{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of convolutional_neural_network_CNN.ipynb","provenance":[{"file_id":"1bASYTc8R9t1m8i9SOnc4qdt0Vwy5tHKc","timestamp":1594849653102}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3DR-eO17geWu"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EMefrVPCg-60"},"source":["### Importing the libraries"]},{"cell_type":"code","metadata":{"id":"FabI-n4PcUiV","colab_type":"code","colab":{}},"source":["# !pip install tensorflow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yG28-1PLcUil","colab_type":"code","colab":{}},"source":["#!pip install keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"s4Yb5p-Rjqkw","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4a657bb3-6f68-4599-ab35-111edbbeecd0"},"source":["import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0mtUGsbxkAT5","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"ca94ba47-f13f-4f29-9f27-c60070149e19"},"source":["tf.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.1.0'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oxQxCBWyoGPE"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MvE-heJNo3GG"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IUjf1Ii3kQ6J","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"a79d2091-7fd7-41b7-ea6f-6f0cd862b668"},"source":["#Image Augmentation : Transvection, horizontal shift, zoom in-out, augmented images\n","# This is necessary for avoiding overfitting\n","train_datagen = ImageDataGenerator(\n","        rescale=1./255, # Feature Scaling. Normalization. All the values become between 0 and 1\n","        shear_range=0.2, \n","        zoom_range=0.2, \n","        horizontal_flip=True)\n","\n","\n","training_set = train_datagen.flow_from_directory(\n","        'dataset/training_set',  # path for the training set\n","        target_size=(64,64),     # final size of the images which are fed to cnn's 64*64 is good choice for faster computation without hampering accuracy\n","        batch_size=32,           #  how many images in each batch\n","        class_mode='binary')     # class mode : binary, since we have binary output dog or cat."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 8000 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mrCMmGw9pHys"},"source":["### Preprocessing the Test set"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RIFERo4-Kh95","colab":{"base_uri":"https://localhost:8080/","height":374},"outputId":"1b387196-7441-428d-a10c-b50d54f6ebf2"},"source":["test_datagen = ImageDataGenerator(rescale=1./255) \n","# we don't apply any transformation/augmentation tpo test set. Only apply feature scaling.\n","\n","test_Set = test_datagen.flow_from_directory(\n","        'dataset/test_set',\n","        target_size=(64, 64), # same size as training set image size\n","        batch_size=32,\n","        class_mode='binary')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"af8O4l90gk7B"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ces1gXY2lmoX"},"source":["### Initialising the CNN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fCUBQtBHLTjd","colab":{}},"source":["# CNN is also sequence of layers so using Sequence class we create cnn as we did in ANN\n","cnn = tf.keras.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u5YJj_XMl5LF"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EkrZpEuFt8s3","colab":{}},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3])) \n","# Since we have 3 channels corresponding to RGB image. input image is 64,64\n","# 32 filters are optimum got by experience"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tf87FpvxmNOJ"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iZUqzS6xvGGx","colab":{}},"source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xaTOgD8rm4mU"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J1MXUVZCxpRb","colab":{}},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')) \n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tmiEuvTunKfk"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gwEzxMzWx3N1","colab":{}},"source":["cnn.add(tf.keras.layers.Flatten())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dAoSECOm203v"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iQzFRwgTx33F","colab":{}},"source":["cnn.add(tf.keras.layers.Dense(units=128 , activation='relu'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yTldFvbX28Na"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LmP1YdK_x4Xe","colab":{}},"source":["cnn.add(tf.keras.layers.Dense(units=1 , activation='sigmoid'))  # units: for binary use 1 not 2.\n","# output activation: softmax for multiclass classification. sigmoid for 2 class(binary) classification"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"D6XkI90snSDl"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vfrFQACEnc6i"},"source":["### Compiling the CNN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IVU9vTZ5y7oD","colab":{}},"source":["cnn.compile(optimizer ='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","# check out implemenation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ehS-v3MIpX2h"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fMjAYxrfO0Xa","colab":{},"outputId":"8161a672-c010-484d-a7a0-1b36dbf41cb8"},"source":["cnn.fit(x = train_generator, validation_data = test_Set, epochs = 1) \n","# epochs = 25 : my pc is primitive so used only 1 for learning purpose. Implemeneted this on kong(gpu) servers made available by university"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","Train for 250 steps, validate for 63 steps\n","250/250 [==============================] - 334s 1s/step - loss: 0.6866 - accuracy: 0.5595 - val_loss: 0.6582 - val_accuracy: 0.6120\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x15f12320>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"U3PZasO0006Z"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n4XoB4IcPod_","colab":{}},"source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg' , target_size =(64,64))\n","test_image = image.img_to_array(test_image) # this converts the image to numpy array format\n","\n","test_image = np.expand_dims(test_image, axis =0) # cnn model expects the image in batch. extra dimension corresponding to batch.\n","# dimesion of the batch which we are adding is the first dimension by specifying axis =0\n","# this has now exact format expected by predict method of cnn\n","\n","result = cnn.predict(test_image)   # this will also have the batch dimension so resukt[][] -first [] batch , second [] prediction\n","training_set.class_indices\n","if (result[0][0]):\n","  prediction = 'dog'\n","else:\n","  prediction = 'cat'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EroQ_imRTu2l","colab":{},"outputId":"dfd2c58b-ad3e-4f70-c6d5-47393985047e"},"source":["print(prediction)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dog\n"],"name":"stdout"}]}]}